{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9425d5b0",
   "metadata": {},
   "source": [
    "# Project: Handwritten Digit Recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9d5abc5",
   "metadata": {},
   "source": [
    "### Name: Duressa Jemal\n",
    "### Id: UGR/3937/12\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8369b6de",
   "metadata": {},
   "source": [
    "# Handwritten Digit Recognition Project\n",
    "\n",
    "In this project, the aim is to develop a convolutional neural network (CNN) model using PyTorch for handwritten digit recognition from the MNIST dataset.\n",
    "\n",
    "## Overview\n",
    "\n",
    "The MNIST dataset consists of 28x28 grayscale images of handwritten digits (0 to 9) along with corresponding labels. The goal is to build a model that accurately classifies these digits.\n",
    "\n",
    "## Approach\n",
    "\n",
    "1. **Data Loading**: The MNIST dataset is loaded and data loaders are created for training and testing.\n",
    "\n",
    "2. **Model Architecture**: The CNN architecture includes convolutional layers, max-pooling, dropout, and fully connected layers.\n",
    "\n",
    "3. **Training**: The Adam optimizer and cross-entropy loss function are used to train the model on the training dataset.\n",
    "\n",
    "4. **Evaluation**: The trained model's performance is evaluated on the test dataset to measure accuracy and generalization.\n",
    "\n",
    "## Project Structure\n",
    "\n",
    "- **Data Preparation**: Loading and preprocessing MNIST images.\n",
    "- **Model Definition**: Defining the CNN architecture.\n",
    "- **Training**: Optimizing model parameters using the training dataset.\n",
    "- **Evaluation**: Assessing model performance on the test dataset.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecd8e717",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "93ba1445",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fdffd50",
   "metadata": {},
   "source": [
    "# Loading MNIST Dataset\n",
    "\n",
    "In this section, we load the MNIST dataset using PyTorch's `datasets.MNIST` module.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "38496047",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = datasets.MNIST(\n",
    "    root = 'data',\n",
    "    train = True,\n",
    "    transform = ToTensor(),\n",
    "    download = True\n",
    ")\n",
    "\n",
    "test_data = datasets.MNIST(\n",
    "    root = 'data',\n",
    "    train = False,\n",
    "    transform = ToTensor(),\n",
    "    download = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "022d80d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset MNIST\n",
       "    Number of datapoints: 10000\n",
       "    Root location: data\n",
       "    Split: Test\n",
       "    StandardTransform\n",
       "Transform: ToTensor()"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6f2e470b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset MNIST\n",
       "    Number of datapoints: 10000\n",
       "    Root location: data\n",
       "    Split: Test\n",
       "    StandardTransform\n",
       "Transform: ToTensor()"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a429097",
   "metadata": {},
   "source": [
    "In this section, we create data loaders for the training and test datasets using PyTorch's `DataLoader` module.\n",
    "\n",
    "### Key Parameters:\n",
    "\n",
    "- `batch_size`: This parameter determines the number of samples in each batch. A smaller batch size might lead to slower convergence, while a larger one might consume more memory.\n",
    "- `shuffle=True`: Setting this parameter to `True` ensures that the data is randomly shuffled before each epoch during training. Shuffling the data helps prevent the model from memorizing the order of samples and encourages better generalization.\n",
    "- `num_workers`: This parameter specifies the number of subprocesses to use for data loading. By default, it's set to 0, meaning that data loading will be done in the main process. However, setting it to a higher value (e.g., 1) can speed up data loading by leveraging multiple CPU cores for parallel processing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3b2af596",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaders = {\n",
    "    'train': DataLoader(train_data,\n",
    "                       batch_size = 100,\n",
    "                       shuffle=True,\n",
    "                       num_workers = 1),\n",
    "    'test': DataLoader(test_data,\n",
    "                       batch_size = 100,\n",
    "                       shuffle=True,\n",
    "                       num_workers = 1)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "873de631",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': <torch.utils.data.dataloader.DataLoader at 0x7f006e87adf0>,\n",
       " 'test': <torch.utils.data.dataloader.DataLoader at 0x7f014c538700>}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50eb7215",
   "metadata": {},
   "source": [
    "# Convolutional Neural Network (CNN) Definition\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e5319a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size = 5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size = 5)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        x = x.view(-1, 320)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        return F.softmax(x, dim=1)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66d27d10",
   "metadata": {},
   "source": [
    "# Training and Evaluation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0c04a093",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cude' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model = CNN().to(device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr = 0.001)\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "def train(epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(loaders['train']):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = loss_fn(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        \n",
    "\n",
    "def test():\n",
    "    model.eval()\n",
    "    \n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data, target in loaders['test']:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += loss_fn(output, target).item()\n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "            correct =+ pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "45fdf28b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(1, 5):\n",
    "    train(epoch)\n",
    "    test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f5308e14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predection: 5\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "model.eval()\n",
    "\n",
    "data, target = test_data[15]\n",
    "\n",
    "data = data.unsqueeze(0).to(device)\n",
    "\n",
    "output = model(data)\n",
    "\n",
    "prediction = output.argmax(dim=1, keepdim=True).item()\n",
    "\n",
    "print(f'Predection: {prediction}')\n",
    "\n",
    "image = data.squeeze(0).squeeze(0).cpu().numpy()\n",
    "\n",
    "plt.imshow(image, cmap='gray')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22816aa8",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "Handwritten digit recognition is a classic machine learning problem with applications in various fields. The CNN model demonstrates effective digit recognition from the MNIST dataset, showcasing the power of deep learning techniques."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
